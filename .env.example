# AI Provider API Keys
# Get your keys from the respective platforms

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic (https://console.anthropic.com/)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Groq (https://console.groq.com/)
GROQ_API_KEY=gsk-your-groq-api-key-here

# LangSmith (optional, for evaluation and observability)
# Get from https://smith.langchain.com/
LANGSMITH_API_KEY=your-langsmith-api-key-here
LANGSMITH_PROJECT=hands-on-ai-engineering

# Model Selection (defaults)
DEFAULT_LLM_PROVIDER=openai  # Options: openai, anthropic, groq, ollama, mock
DEFAULT_EMBEDDING_PROVIDER=openai  # Options: openai, sentence-transformers

# Model Names
OPENAI_MODEL=gpt-3.5-turbo  # or gpt-4, gpt-4-turbo
ANTHROPIC_MODEL=claude-3-sonnet-20240229  # or claude-3-opus, claude-3-haiku
GROQ_MODEL=mixtral-8x7b-32768  # or llama2-70b-4096

# Embeddings
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
SENTENCE_TRANSFORMER_MODEL=all-MiniLM-L6-v2

# Vector Store
CHROMA_PERSIST_DIR=./chroma_db
VECTOR_STORE_COLLECTION=civil_engineering_docs

# Chunking Configuration
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200
DEFAULT_CHUNKING_STRATEGY=recursive  # Options: fixed, recursive, semantic, sentence

# LLM Configuration
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000
STREAMING_ENABLED=true

# Agent Configuration
MAX_AGENT_ITERATIONS=5
AGENT_TIMEOUT_SECONDS=60

# Application
DEBUG=false
LOG_LEVEL=INFO

# Ollama (if using local models)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=mistral

# Cost Tracking (optional)
TRACK_COSTS=true