# Copy to .env and fill in your actual API keys

# ============================================================================
# LLM Provider API Keys (Multi-Provider Fallback)
# ============================================================================
# The system will try providers in this priority order:
# 1. OpenAI → 2. Cohere → 3. Gemini → 4. Grok → 5. Mistral → 6. HuggingFace → 7. Ollama → 8. MockLLM
# Set at least one key to use real LLM providers, or leave all blank to use MockLLM

# OpenAI (GPT-4o, GPT-4o-mini)
OPENAI_API_KEY=your-openai-key-here

# Cohere (Command R+, Command R)
COHERE_API_KEY=your-cohere-key-here

# Google Gemini (Gemini 1.5 Pro, Gemini 1.5 Flash)
GOOGLE_API_KEY=your-google-key-here
# Alternative Gemini key (if you have multiple)
GOOGLE_API_KEY_2=your-second-google-key-here

# xAI Grok
XAI_API_KEY=your-xai-key-here

# Mistral AI
MISTRAL_API_KEY=your-mistral-key-here

# HuggingFace Inference API
HUGGINGFACE_API_KEY=your-huggingface-key-here

# LangChain API Keys
LANGCHAIN_API_KEY=your-langchain-key-here
LANGCHAIN_API_KEY_2=your-second-langchain-key-here

# Ollama (local models - no key needed, just ensure Ollama is running)
# OLLAMA_HOST=http://localhost:11434

# ============================================================================
# AITEA Configuration
# ============================================================================
AITEA_DATA_DIR=./data
AITEA_LOG_LEVEL=INFO

# ============================================================================
# Optional: Observability & Monitoring
# ============================================================================
# LANGSMITH_API_KEY=your-langsmith-key-here
# LANGFUSE_PUBLIC_KEY=your-langfuse-public-key-here
# LANGFUSE_SECRET_KEY=your-langfuse-secret-key-here
